{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n",
    "from scipy import ndimage\n",
    "from skimage import exposure ,metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dispay Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_images():\n",
    "    root = tk.Tk()\n",
    "    root.wm_attributes('-topmost', 1)\n",
    "    root.withdraw()\n",
    "\n",
    "    file_paths = filedialog.askopenfilenames(title=\"Select Image Files\", filetypes=[(\"Image files\", \"*.jpg;*.jpeg;*.png;*.gif;*.tif;*.bmp;\")])\n",
    "    if file_paths:\n",
    "        image = cv2.imread(file_paths[0])\n",
    "        image = cv2.resize(image, (640, 480))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disp_img(img , title = 'img' ,text = {'text' : [None],'loc':[(165,500)]}):\n",
    "    \n",
    "    def mouse_callback(event, x, y, flags, param):\n",
    "        if event == cv2.EVENT_RBUTTONUP:\n",
    "            cv2.destroyAllWindows()\n",
    "    \n",
    "    I = img.copy()\n",
    "    avg = np.mean(I)\n",
    "    for  i , val  in  enumerate(text['text']):\n",
    "        if avg> 128:\n",
    "            cv2.putText(I, val, text['loc'][i], cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1)\n",
    "        else:  \n",
    "            cv2.putText(I, val, text['loc'][i], cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1) \n",
    "\n",
    "    cv2.imshow(title ,I)\n",
    "    cv2.setWindowProperty(title, cv2.WND_PROP_TOPMOST, 1)\n",
    "    # Associate the callback function with the named window\n",
    "    cv2.setMouseCallback(title, mouse_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Enhencement Algorithms and Metrics Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################### Convert Color Spaces #####################################\n",
    "def BGRtoHSV(BGR):\n",
    "    hsv = cv2.cvtColor(BGR, cv2.COLOR_BGR2HSV)\n",
    "    return cv2.split(hsv)\n",
    "\n",
    "def HSVtoBGR(H,S,V):\n",
    "    hsv = np.stack([H,S,V],axis=2)\n",
    "    bgr = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "    return bgr\n",
    "\n",
    "################################################ Denoise TV  #########################################\n",
    "def denoise_tv(image, weight=1/90, eps=1.e-6, max_num_iter=200):\n",
    "    \"\"\"Perform total-variation denoising on n-dimensional images.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image : ndarray\n",
    "        n-D input data to be denoised.\n",
    "    weight : float, optional\n",
    "        Denoising weight It is equal to 1/lambda . The greater `weight`, the more denoising .\n",
    "        \n",
    "    eps : float, optional\n",
    "        Relative difference of the value of the cost function that determines\n",
    "        the stop criterion. The algorithm stops when:\n",
    "            (E_(n-1) - E_n) < eps * E_0\n",
    "        where E_0 is the initial value of the cost function.    \n",
    "\n",
    "    max_num_iter : int, optional\n",
    "        Maximal number of iterations used for the optimization.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out : ndarray\n",
    "        Denoised array  uint8 [0 - 255].\n",
    "    \"\"\"\n",
    "    image = image.astype(np.float64) # convert image to float\n",
    "    ndim = image.ndim\n",
    "    p = np.zeros((image.ndim, ) + image.shape, dtype=image.dtype)\n",
    "    g = np.zeros_like(p)\n",
    "    d = np.zeros_like(image)\n",
    "    i = 0\n",
    "    while i < max_num_iter:\n",
    "        if i > 0:\n",
    "            # d will be the (negative) divergence of p\n",
    "            d = -p.sum(0)\n",
    "            slices_d = [slice(None), ] * ndim\n",
    "            slices_p = [slice(None), ] * (ndim + 1)\n",
    "            for ax in range(ndim):\n",
    "                slices_d[ax] = slice(1, None)\n",
    "                slices_p[ax+1] = slice(0, -1)\n",
    "                slices_p[0] = ax\n",
    "                d[tuple(slices_d)] += p[tuple(slices_p)]\n",
    "                slices_d[ax] = slice(None)\n",
    "                slices_p[ax+1] = slice(None)\n",
    "            out = image + d\n",
    "        else:\n",
    "            out = image\n",
    "        E = (d ** 2).sum()\n",
    "\n",
    "        # g stores the gradients of out along each axis\n",
    "        # e.g. g[0] is the first order finite difference along axis 0\n",
    "        slices_g = [slice(None), ] * (ndim + 1)\n",
    "        for ax in range(ndim):\n",
    "            slices_g[ax+1] = slice(0, -1)\n",
    "            slices_g[0] = ax\n",
    "            g[tuple(slices_g)] = np.diff(out, axis=ax)\n",
    "            slices_g[ax+1] = slice(None)\n",
    "\n",
    "        norm = np.sqrt((g ** 2).sum(axis=0))[np.newaxis, ...] # calculate magnitude\n",
    "        E += weight * norm.sum() # Update cost function\n",
    "        tau = 1. / (2.*ndim) # calc step \n",
    "        norm *= tau / weight\n",
    "        norm += 1.\n",
    "        p -= tau * g\n",
    "        p /= norm\n",
    "        E /= float(image.size)\n",
    "        if i == 0:\n",
    "            E_init = E\n",
    "            E_previous = E\n",
    "        else:\n",
    "            if np.abs(E_previous - E) < eps * E_init:\n",
    "                break\n",
    "            else:\n",
    "                E_previous = E\n",
    "        i += 1\n",
    "    print(i,tau)    \n",
    "    return out.astype(np.uint8)\n",
    "\n",
    "######################################## Adaptive Gamma Correction ###################################\n",
    "def adaptive_gamma_transform(img, n,m):\n",
    "    \"\"\"\n",
    "    Applies adaptive gamma transform on a given image.\n",
    "\n",
    "    Args:\n",
    "        img: A grayscale image to be processed.\n",
    "        m: Size of the local area (height).\n",
    "        n: Size of the local area (width).\n",
    "\n",
    "    Returns:\n",
    "        A gamma corrected image.\n",
    "    \"\"\"\n",
    "    rows, cols = img.shape\n",
    "    gamma_corrected = np.zeros((rows, cols))\n",
    "\n",
    "    # Add small value to ignore zero division error and convert to float\n",
    "    img = (img+1.)/255. \n",
    "\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            rmin = max(0, i - m//2)\n",
    "            rmax = min(rows, i + m//2 + 1)\n",
    "            cmin = max(0, j - n//2)\n",
    "            cmax = min(cols, j + n//2 + 1)\n",
    "            local_area = img[rmin:rmax, cmin:cmax]\n",
    "\n",
    "            N = np.mean(local_area) # calculate mean on local area n x m\n",
    "            b = np.var(local_area)  # calculate var on local area n x m\n",
    "\n",
    "            # Calculate the gamma value.\n",
    "            gamma = N/img[i,j] + b\n",
    "\n",
    "            # Gamma correct the pixel value.\n",
    "            gamma_corrected[i,j] = np.power(img[i,j], gamma)\n",
    "\n",
    "    return (gamma_corrected*255).astype(np.uint8) # transform back to uint8 [0 - 255]\n",
    "\n",
    "#################################################### MSR #############################################\n",
    "def get_ksize(sigma):\n",
    "    # Opencv calculates ksize from sigma as\n",
    "    # sigma = 0.3*((ksize-1)*0.5 - 1) + 0.8\n",
    "    # then ksize from sigma is\n",
    "    # ksize = ((sigma - 0.8)/0.15) + 2.0\n",
    "\n",
    "    return int(((sigma - 0.8)/0.15) + 2.0)\n",
    "\n",
    "def get_gaussian_blur(img, ksize=0, sigma=5):\n",
    "    # Perform convolution I(i,j)*G(i,j)\n",
    "    # if ksize == 0, then compute ksize from sigma\n",
    "    if ksize == 0:\n",
    "        ksize = get_ksize(sigma)\n",
    "    \n",
    "    # Gaussian 2D-kernel can be seperable into 2-orthogonal vectors\n",
    "    # then compute full kernel by taking outer product or simply mul(V, V.T)\n",
    "    sep_k = cv2.getGaussianKernel(ksize, sigma)\n",
    "\n",
    "    return cv2.filter2D(img, -1, np.outer(sep_k, sep_k))\n",
    "\n",
    "def ssr(img, sigma):\n",
    "    # Single-scale retinex of an image\n",
    "    # SSR(x, y) = log(I(x, y)) - log(I(x, y)*G(x, y))\n",
    "    # G = surrounding function,( Gaussian )\n",
    "    \n",
    "    return np.log10(img) - np.log10(get_gaussian_blur(img, ksize=0, sigma=sigma) + 1.0)\n",
    "\n",
    "def msr(img, sigma_scales=[15, 80, 250],apply_normalization=True):\n",
    "    # Multi-scale retinex of an image\n",
    "    # MSR(x,y) = sum(weight[i]*SSR(x,y, scale[i])), i = {1..n} scales\n",
    "    img = img + 1.0 # add small value to ignore log(0)\n",
    "    msr = np.zeros(img.shape)\n",
    "    # for each sigma scale compute SSR\n",
    "    for sigma in sigma_scales:\n",
    "        msr += ssr(img, sigma)\n",
    "    \n",
    "    # divide MSR by weights of each scale\n",
    "    # here we use equal weights \n",
    "    msr = msr / len(sigma_scales)\n",
    "    \n",
    "    # computed MSR could be in range [-k, +l], k and l could be any real value\n",
    "    # so normalize the MSR image values in range [0, 255]\n",
    "    if apply_normalization: \n",
    "       return cv2.normalize(msr, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8UC3)\n",
    "    else: \n",
    "       return msr\n",
    "\n",
    "\n",
    "############################### Multi-scale Hyperbolic Tangent Enhancement ###########################\n",
    "def tanh(img, sigma):\n",
    "    # Single-scale Hyperbolic Tangent Enhancement\n",
    "    # tanh(I(x,y) / (I(x, y)*G(x, y)))\n",
    "    # G = surrounding function,( Gaussian )\n",
    "    return np.tanh(img/get_gaussian_blur(img, ksize=0, sigma=sigma))\n",
    "\n",
    "def mtanh(img, sigma_scales=[15, 80, 250]):\n",
    "    # Multi-scale Hyperbolic Tangent Enhancement\n",
    "    img = img + 1.0 # add small value to ignore zero division\n",
    "    i_t = np.zeros(img.shape)\n",
    "    # for each sigma scale compute tanh\n",
    "    for sigma in sigma_scales:\n",
    "        i_t += tanh(img, sigma)\n",
    "    \n",
    "    # divide tanh by weights of each scale\n",
    "    # here we use equal weights 1/3\n",
    "    i_t = i_t / len(sigma_scales)\n",
    "    \n",
    "    return (i_t*255).astype(np.uint8) # transform back to uint8 [0 - 255]\n",
    "\n",
    "\n",
    "################################### Double-Function Image Enhancement ################################\n",
    "def DFIE(img , sigma=[10,40,300],n = 3,m= 3):\n",
    "    i_l = msr(img,sigma).astype(np.float64) # calculate  weighted MSR\n",
    "    i_t = mtanh(img,sigma).astype(np.float64) # calculate  weighted tanh\n",
    "    \n",
    "    # Using gausian to estimate mean , much faster than do in in loop\n",
    "    i_l_mean = cv2.blur(i_l, (n, m))\n",
    "    i_t_mean = cv2.blur(i_t, (n, m))\n",
    "    a= i_t_mean/i_l_mean\n",
    "    alpha = cv2.normalize(a, None, 0, 1.0, cv2.NORM_MINMAX, dtype=cv2.CV_64F)\n",
    "    \n",
    "    balanced = alpha*i_l + (1-alpha)*i_t\n",
    "   \n",
    "    # # Same as above but take much longer to calculate\n",
    "    # rows, cols = img.shape\n",
    "    # balanced = np.zeros((rows, cols))\n",
    "\n",
    "    # for i in range(rows):\n",
    "    #     for j in range(cols):\n",
    "    #         rmin = max(0, i - m//2)\n",
    "    #         rmax = min(rows, i + m//2 + 1)\n",
    "    #         cmin = max(0, j - n//2)\n",
    "    #         cmax = min(cols, j + n//2 + 1)\n",
    "    #         # Calculate the indices for the local area.\n",
    "    #         local_i_l = i_l[rmin:rmax, cmin:cmax]\n",
    "    #         local_i_t = i_t[rmin:rmax, cmin:cmax]\n",
    "    #         alpha = np.mean(local_i_t)/np.mean(local_i_l)\n",
    "    #         balanced[i,j] = alpha*i_l[i,j]+(1-alpha)*i_t[i,j]\n",
    "\n",
    "    return balanced.astype(np.uint8) # transform back to uint8 [0 - 255]\n",
    "\n",
    "\n",
    "################################## Three-Dimensional Gamma Correction ################################\n",
    "def three_dim_gamma_correction(image, weights=[0.05,0.05,0.2], n=3, m=3):\n",
    "    # add some small value to ignore zerro division and convert to float [0.0 - 1.0]\n",
    "    image = (image+1.)/255. \n",
    "    # Initialize output image\n",
    "    output_image = np.zeros_like(image)\n",
    "    rows, cols = image.shape\n",
    "    \n",
    "    gx = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    gy = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    Gr =np.hypot(gx,gy) # calculate magnitude, same as sqrt(gx**2 +gy**2)\n",
    "    # Iterate over each pixel in the input image\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            rmin = max(0, i - m//2)\n",
    "            rmax = min(rows, i + m//2 + 1)\n",
    "            cmin = max(0, j - n//2)\n",
    "            cmax = min(cols, j + n//2 + 1)\n",
    "            # Extract local region of size n x m around the pixel\n",
    "            local_region = image[rmin:rmax, cmin:cmax]\n",
    "            # Compute local maximum, mean gradient, and variance\n",
    "            local_max = np.max(local_region)\n",
    "            local_mean_gradient = np.mean(Gr[i:i+n, j:j+m])\n",
    "            local_variance = np.var(local_region)\n",
    "\n",
    "            # Compute gamma correction factor based on local statistics and weights\n",
    "            gamma = weights[0]*np.exp(image[i,j]/local_max) + weights[1]*np.exp(local_mean_gradient) + weights[2]*np.exp(local_variance)\n",
    "\n",
    "            # Apply gamma correction to pixel value\n",
    "            output_image[i,j] = np.power(image[i,j],gamma)*255\n",
    "\n",
    "    return output_image.astype(np.uint8) # transform back to uint8 [0 - 255]\n",
    "\n",
    "#################################### Adaptive Saturation  Correction #################################\n",
    "\n",
    "def adaptive_saturation_adjustment(s_channel,n,m):\n",
    "    # add some small value to ignore zerro division and convert to float [0.0 - 1.0]\n",
    "    s_channel= (s_channel+1.)/255\n",
    "    rows, cols = s_channel.shape\n",
    "    saturation_corrected = np.zeros((rows, cols))\n",
    "\n",
    "    # Get x-gradient in \"sx\"\n",
    "    sx = cv2.Sobel(s_channel, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    # Get y-gradient in \"sy\"\n",
    "    sy = cv2.Sobel(s_channel, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    # Get square root of sum of squares\n",
    "\n",
    "    Sg=np.hypot(sx,sy)\n",
    "    \n",
    "    # # Compute the global mean value of the S channel\n",
    "    S_mean = np.mean(s_channel)\n",
    "\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            rmin = max(0, i - m//2)\n",
    "            rmax = min(rows, i + m//2 + 1)\n",
    "            cmin = max(0, j - n//2)\n",
    "            cmax = min(cols, j + n//2 + 1)\n",
    "            # Extract local region of size n x m around the pixel\n",
    "            local_region = s_channel[rmin:rmax, cmin:cmax]\n",
    "            # Calculate the average  of the local area.\n",
    "            Sm = np.mean(local_region)\n",
    "\n",
    "            # Apply regulation\n",
    "            if s_channel[i,j] <= S_mean+Sg[i,j]:\n",
    "                saturation_corrected[i,j] = 1+0.8*np.log10(Sm/(s_channel[i,j]+0.5*Sg[i,j]))   \n",
    "            else:\n",
    "                saturation_corrected[i,j] = np.exp((Sm-s_channel[i,j])/2)\n",
    "    \n",
    "    return  cv2.normalize(saturation_corrected, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8UC3)\n",
    "\n",
    "############################### Multi Scale Retinex with Color Restoration ###########################\n",
    "def color_balance(img, low_per, high_per):\n",
    "    '''Contrast stretch img by histogram equilization with black and white cap'''\n",
    "    \n",
    "    tot_pix = img.shape[1] * img.shape[0]\n",
    "    # no.of pixels to black-out and white-out\n",
    "    low_count = tot_pix * low_per / 100\n",
    "    high_count = tot_pix * (100 - high_per) / 100\n",
    "\n",
    "    # channels of image\n",
    "    ch_list = []\n",
    "    if len(img.shape) == 2:\n",
    "        ch_list = [img]\n",
    "    else:\n",
    "        ch_list = cv2.split(img)\n",
    "    \n",
    "    cs_img = []\n",
    "    # for each channel, apply contrast-stretch\n",
    "    for i in range(len(ch_list)):\n",
    "        ch = ch_list[i]\n",
    "        # cummulative histogram sum of channel\n",
    "        cum_hist_sum = np.cumsum(cv2.calcHist([ch], [0], None, [256], (0, 256)))\n",
    "\n",
    "        # find indices for blacking and whiting out pixels\n",
    "        li, hi = np.searchsorted(cum_hist_sum, (low_count, high_count))\n",
    "        if (li == hi):\n",
    "            cs_img.append(ch)\n",
    "            continue\n",
    "        # lut with min-max normalization for [0-255] bins\n",
    "        lut = np.array([0 if i < li \n",
    "                        else (255 if i > hi else round((i - li) / (hi - li) * 255)) \n",
    "                        for i in np.arange(0, 256)], dtype = 'uint8')\n",
    "        # constrast-stretch channel\n",
    "        cs_ch = cv2.LUT(ch, lut)\n",
    "        cs_img.append(cs_ch)\n",
    "    \n",
    "    if len(cs_img) == 1:\n",
    "        return np.squeeze(cs_img)\n",
    "    elif len(cs_img) > 1:\n",
    "        return cv2.merge(cs_img)\n",
    "    return None\n",
    "\n",
    "def msrcr(img, sigma_scales=[15, 80, 250], alpha=125, beta=46, G=192, b=-30, low_per=1, high_per=1):\n",
    "    # Multi-scale retinex with Color Restoration\n",
    "    # MSRCR(x,y) = G * [MSR(x,y)*CRF(x,y) - b], G=gain and b=offset\n",
    "    # CRF(x,y) = beta*[log(alpha*I(x,y) - log(I'(x,y))]\n",
    "    # I'(x,y) = sum(Ic(x,y)), c={0...k-1}, k=no.of channels\n",
    "    \n",
    "    img = img + 1.0\n",
    "    # Multi-scale retinex and don't normalize the output\n",
    "    msr_img = msr(img, sigma_scales, apply_normalization=False)\n",
    "    # Color-restoration function\n",
    "    crf = beta * (np.log10(alpha * img) - np.log10(np.sum(img, axis=2, keepdims=True)))\n",
    "    # MSRCR\n",
    "    msrcr = G * (msr_img*crf - b)\n",
    "    # normalize MSRCR\n",
    "    msrcr = cv2.normalize(msrcr, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8UC3)\n",
    "    # color balance the final MSRCR to flat the histogram distribution with tails on both sides\n",
    "    msrcr = color_balance(msrcr, low_per, high_per)\n",
    "    \n",
    "    return msrcr\n",
    "\n",
    "\n",
    "################################################# CLAHE ##############################################\n",
    "def CLAHE(Img):\n",
    "    # Convert image to LAB color space\n",
    "    lab = cv2.cvtColor(Img, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    # Split LAB image into separate channels\n",
    "    l, a, b = cv2.split(lab)\n",
    "\n",
    "    # Apply CLAHE to L channel\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "    cl = clahe.apply(l)\n",
    "\n",
    "    # Merge the CLAHE enhanced L channel with the other LAB channels\n",
    "    lab_cl = cv2.merge((cl,a,b))\n",
    "\n",
    "    # Convert back to RGB color space\n",
    "    final = cv2.cvtColor(lab_cl, cv2.COLOR_LAB2BGR)\n",
    "    return final \n",
    "\n",
    "################################### Adaptive histogram equalization ##################################\n",
    "def AHE(Img):\n",
    "    I = cv2.cvtColor(Img, cv2.COLOR_BGR2RGB)\n",
    "    eq = exposure.equalize_adapthist(Img)\n",
    "    return cv2.normalize(eq, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8UC3)\n",
    "    \n",
    "    \n",
    "################################################ Metrics #############################################\n",
    "def PSNR(I_r, I_f):\n",
    "    mse = np.mean((I_r - I_f) ** 2)\n",
    "    max_pixel = 255\n",
    "    psnr = 10 * np.log10(max_pixel ** 2 / mse)\n",
    "    # psnr = 20 * np.log10(max_pixel/np.sqrt(mse))\n",
    "    return round(psnr, 4)\n",
    "\n",
    "\n",
    "def SD(I_f):\n",
    "    # Compute the histogram\n",
    "    hist, bins = np.histogram(I_f.flatten(), bins=256)\n",
    "    # Compute the mean of the histogram\n",
    "    mean = np.sum(hist * bins[:-1]) / np.sum(hist)\n",
    "\n",
    "    # Compute the variance of the histogram\n",
    "    variance = np.sum((bins[:-1] - mean) ** 2 * hist) / np.sum(hist)\n",
    "\n",
    "    # Compute the standard deviation of the histogram\n",
    "    return round(np.sqrt(variance), 4)\n",
    "\n",
    "\n",
    "\n",
    "def SSIM(I_r, I_f, L=255):\n",
    "    K1 = 0.01\n",
    "    K2 = 0.03\n",
    "    C1 = (K1 * L) ** 2\n",
    "    C2 = (K2 * L) ** 2\n",
    "    # INITS\n",
    "    I2_2 = I_f ** 2  # I2^2\n",
    "    I1_2 = I_r ** 2  # I1^2\n",
    "    I1_I2 = I_r * I_f  # I1 * I2\n",
    "    # END INITS\n",
    "    # PRELIMINARY COMPUTING\n",
    "    mu1 = cv2.GaussianBlur(I_r, (11, 11), 1.5)\n",
    "    mu2 = cv2.GaussianBlur(I_f, (11, 11), 1.5)\n",
    "    mu1_2 = mu1 ** 2\n",
    "    mu2_2 = mu2 ** 2\n",
    "    mu1_mu2 = mu1 * mu2\n",
    "    sigma1_2 = cv2.GaussianBlur(I1_2, (11, 11), 1.5)\n",
    "    sigma1_2 -= mu1_2\n",
    "    sigma2_2 = cv2.GaussianBlur(I2_2, (11, 11), 1.5)\n",
    "    sigma2_2 -= mu2_2\n",
    "    sigma12 = cv2.GaussianBlur(I1_I2, (11, 11), 1.5)\n",
    "    sigma12 -= mu1_mu2\n",
    "    t1 = 2 * mu1_mu2 + C1\n",
    "    t2 = 2 * sigma12 + C2\n",
    "    t3 = t1 * t2  # t3 = ((2*mu1_mu2 + C1).*(2*sigma12 + C2))\n",
    "    t1 = mu1_2 + mu2_2 + C1\n",
    "    t2 = sigma1_2 + sigma2_2 + C2\n",
    "    t1 = t1 * t2  # t1 =((mu1_2 + mu2_2 + C1).*(sigma1_2 + sigma2_2 + C2))\n",
    "    ssim_map = t3 / t1\n",
    "    mssim = np.mean(ssim_map)  # mssim = average of ssim map\n",
    "    return round(mssim, 4)\n",
    "\n",
    "\n",
    "def IE(I_f):\n",
    "    # Add epsilon to avoid division by zero errors\n",
    "    epsilon = 2**(-32) \n",
    "    # Compute the histogram of the image\n",
    "    hist, _ = np.histogram(I_f.flatten(), bins=256)\n",
    "\n",
    "    # Calculate the total number of pixels in the image\n",
    "    num_pixels = np.sum(hist) # same as N*M\n",
    "\n",
    "    # Calculate the PMF by dividing each bin in the histogram by the total number of pixels\n",
    "    hist_p = hist / num_pixels\n",
    "\n",
    "    hist_p = np.clip(hist_p, epsilon, 1)\n",
    "    E = -np.sum(hist_p * np.log2(hist_p))\n",
    "    return round(E, 4)\n",
    "\n",
    "\n",
    "def metric(I_ref ,I_enc):\n",
    "    I_ref_gray = cv2.cvtColor(I_ref, cv2.COLOR_BGR2GRAY).astype(np.float64)\n",
    "    I_enc_gray = cv2.cvtColor(I_enc, cv2.COLOR_BGR2GRAY).astype(np.float64)\n",
    "    info_ref = {'PSNR': PSNR(I_ref_gray, I_enc_gray),'SSIM': SSIM(I_ref_gray, I_enc_gray, L=255) ,'SD': SD(I_enc_gray) ,'IE':IE(I_enc_gray)}\n",
    "    return info_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models folding into one function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model(Img ,model = 'DFE' ,disp_selector = [False ,False,False ,False,False ,False, False ,False]\n",
    "           ,sigma = [10,40,400],weights=[0.05,0.05,0.2], kernel = [9,9],lam = 40):\n",
    "    \n",
    "      if model == 'DFE':\n",
    "         # disp_selector = [Original , Original & I_o,  HSV ,I_d,I_p,I_out,I_img,I_u,S_tag ]\n",
    "         h,s,v = BGRtoHSV(Img) \n",
    "         n , m = kernel\n",
    "         ######################### V - Channel #########################\n",
    "         I_u_V= denoise_tv(v, weight =1/lam, eps=1e-6, max_num_iter=100)\n",
    "         I_d = adaptive_gamma_transform(I_u_V,n=3,m=3)\n",
    "         I_p = DFIE(I_d , sigma,n ,m )\n",
    "         I_out = three_dim_gamma_correction(I_d,weights,n,m)\n",
    "         I_img = ((I_out/255.*I_p/255.)*255).astype(np.uint8)\n",
    "\n",
    "         ######################### S - Channel #########################\n",
    "         I_u= denoise_tv(s, weight=1/40, eps=1e-6, max_num_iter=100)\n",
    "         S_tag = exposure.equalize_adapthist(I_u/255.)\n",
    "         S_tag = cv2.normalize(S_tag, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8UC3)\n",
    "         \n",
    "         ############################# I_o #############################\n",
    "         I_o = HSVtoBGR(h,S_tag,I_img)\n",
    "         I_o = HSVtoBGR(h,I_u,I_img)\n",
    "         I_o_cb = color_balance(I_o,1,1)\n",
    "         performance = metric(Img,I_o)\n",
    "         if disp_selector[0]:\n",
    "            disp_img(np.block([[Img],[I_o],[I_o_cb]]) , title = 'Enhancement' ,text = {'text' : ['Original','Enhancement','Enhancement + Color Balance'],'loc':[(280,460),(640+280,460),(640*2+230,460)]})     \n",
    "         if disp_selector[1]:\n",
    "            disp_img(np.block([h,s,v]) , title = 'HSV' ,text = {'text' : ['h-channel','s-channel','v-channel'],'loc':[(280,460),(640+280,460),(640*2+280,460)]})  \n",
    "         if disp_selector[2]:\n",
    "            disp_img(I_d, title = 'I_d' ,text = {'text' : ['I_d'],'loc':[(280,460)]})\n",
    "         if disp_selector[3]:\n",
    "            disp_img(I_p, title = 'I_p' ,text = {'text' : ['I_p'],'loc':[(280,460)]})\n",
    "         if disp_selector[4]:\n",
    "            disp_img(I_out, title = 'I_out' ,text = {'text' : ['I_out'],'loc':[(280,460)]})\n",
    "         if disp_selector[5]:\n",
    "            disp_img(I_img, title = 'I_img' ,text = {'text' : ['I_img'],'loc':[(280,460)]})\n",
    "         if disp_selector[6]:\n",
    "            disp_img(I_u, title = 'I_u' ,text = {'text' : ['I_u'],'loc':[(280,460)]})\n",
    "         if disp_selector[7]:\n",
    "            disp_img(S_tag, title = 'S_tag' ,text = {'text' : ['S_tag'],'loc':[(280,460)]})\n",
    "         return  performance\n",
    "      if model == 'MSRCR':\n",
    "         I_o = msrcr(Img,sigma_scales=sigma) \n",
    "         performance = metric(Img,I_o)\n",
    "         if disp_selector[0]:\n",
    "            disp_img(np.block([[Img],[I_o]]) , title = 'Enhancement' ,text = {'text' : ['Original','Enhancement'],'loc':[(280,460),(640+280,460)]})\n",
    "\n",
    "         return  performance    \n",
    "      if model == 'CLAHE':\n",
    "         I_o = CLAHE(Img) \n",
    "         performance = metric(Img,I_o)\n",
    "\n",
    "         if disp_selector[0]:\n",
    "            disp_img(np.block([[Img],[I_o]]) , title = 'Enhancement' ,text = {'text' : ['Original','Enhancement'],'loc':[(280,460),(640+280,460)]})  \n",
    "\n",
    "         return  performance            \n",
    "      if model == 'AHE':\n",
    "         I_o = AHE(Img)\n",
    "         performance = metric(Img,I_o) \n",
    "\n",
    "         if disp_selector[0]:\n",
    "            disp_img(np.block([[Img],[I_o]]) , title = 'Enhancement' ,text = {'text' : ['Original','Enhancement'],'loc':[(280,460),(640+280,460)]}) \n",
    " \n",
    "         return  performance         \n",
    "             "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load images and Convert to HSV color space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Img =select_images()\n",
    "h,s,v = BGRtoHSV(Img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate diffirent models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PSNR': 19.8661, 'SSIM': 0.7196, 'SD': 44.1037, 'IE': 6.8306}\n"
     ]
    }
   ],
   "source": [
    "disp_selector = [True ,0,0 ,0 ,0 ,0 ,0 ,0]\n",
    "performance = Model(Img ,model = 'AHE' ,disp_selector =disp_selector)\n",
    "print(performance)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PSNR': 18.3605, 'SSIM': 0.6047, 'SD': 45.4709, 'IE': 6.7732}\n"
     ]
    }
   ],
   "source": [
    "disp_selector = [True ,0,0 ,0 ,0 ,0 ,0 ,0]\n",
    "performance = Model(Img ,model = 'CLAHE' ,disp_selector =disp_selector)\n",
    "print(performance)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PSNR': 6.8239, 'SSIM': 0.2431, 'SD': 57.4856, 'IE': 7.6435}\n"
     ]
    }
   ],
   "source": [
    "disp_selector = [True ,0,0 ,0 ,0 ,0 ,0 ,0]\n",
    "performance = Model(Img ,model = 'MSRCR' ,disp_selector =disp_selector\n",
    "           ,sigma = [30,100,300])\n",
    "print(performance)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 0.25\n",
      "16 0.25\n",
      "{'PSNR': 15.1042, 'SSIM': 0.4536, 'SD': 42.673, 'IE': 7.115}\n"
     ]
    }
   ],
   "source": [
    "disp_selector = [True ,True,True ,True ,True ,True ,True ,True]\n",
    "performance = Model(Img ,model = 'DFE' ,disp_selector =disp_selector\n",
    "           ,sigma = [30,100,300],weights=[0.01,0.01,0.25],kernel = [9,9],lam =40)\n",
    "print(performance)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import ttk\n",
    "\n",
    "class ImageProcessorGUI:\n",
    "\n",
    "    def __init__(self, master):\n",
    "        self.master = master\n",
    "        master.title(\"Image Processor\")\n",
    "        w = 380\n",
    "        h = 350\n",
    "        # open window in the center of screen\n",
    "        screen_width = master.winfo_screenwidth()  # get the screen width\n",
    "        screen_height = master.winfo_screenheight()  # get the screen height\n",
    "        x = int((screen_width / 2) - (w / 2))\n",
    "        y = int((screen_height / 2) - (h / 2))\n",
    "        master.geometry('{}x{}+{}+{}'.format(w, h, x, y))  # window.geometry('wxh+x+y')\n",
    "            \n",
    "        # Select image button\n",
    "        self.select_image_button = tk.Button(master, text=\"Select Image\", command=self.select_image)\n",
    "        self.select_image_button.grid(row=0, column=0, padx=10, pady=10)\n",
    "\n",
    "        # Display Image button\n",
    "        self.select_image_button = tk.Button(master, text=\"Display Selected\",state='disabled', command= self.display_selected)\n",
    "        self.select_image_button.grid(row=0, column=1, padx=10, pady=10)\n",
    "        \n",
    "        # Model combobox\n",
    "        self.model_label = tk.Label(master, text=\"Select Model:\")\n",
    "        self.model_label.grid(row=1, column=0, padx=10, pady=5)\n",
    "        \n",
    "        self.model_combobox = ttk.Combobox(master, values=['MSRCR', 'CLAHE', 'AHE', 'DFE'],textvariable= 'Select',state='disabled')\n",
    "        self.model_combobox.bind(\"<<ComboboxSelected>>\", self.en)\n",
    "        self.model_combobox.grid(row=1, column=1, padx=10, pady=5)\n",
    "        \n",
    "        # Value entries\n",
    "        self.values_label_sigma = tk.Label(master, text=\"Enter Sigma values :\")\n",
    "        self.values_label_sigma.grid(row=2, column=0, padx=10, pady=5)\n",
    "        \n",
    "        self.values_entry_sigma = tk.Entry(master,state='disabled')\n",
    "        self.values_entry_sigma.grid(row=2, column=1, padx=10, pady=5 )\n",
    "\n",
    "        self.values_label_weight = tk.Label(master, text=\"Enter Weight values :\")\n",
    "        self.values_label_weight.grid(row=3, column=0, padx=10, pady=5)\n",
    "        \n",
    "        self.values_entry_weight = tk.Entry(master,state='disabled')\n",
    "        self.values_entry_weight.grid(row=3, column=1, padx=10, pady=5)\n",
    "\n",
    "        \n",
    "        self.values_label_kernel = tk.Label(master, text=\"Enter Kernel size (n,m) :\")\n",
    "        self.values_label_kernel.grid(row=4, column=0, padx=10, pady=5)\n",
    "        \n",
    "        self.values_entry_kernel= tk.Entry(master,state='disabled')\n",
    "        self.values_entry_kernel.grid(row=4, column=1, padx=10, pady=5)\n",
    "\n",
    "        \n",
    "        self.values_label_lambda = tk.Label(master, text=\"Enter Lambda value :\")\n",
    "        self.values_label_lambda.grid(row=5, column=0, padx=10, pady=5)\n",
    "        \n",
    "        self.values_entry_lambda = tk.Entry(master,state='disabled')\n",
    "        self.values_entry_lambda.grid(row=5, column=1, padx=10, pady=5)\n",
    "        \n",
    "        # Checkboxes\n",
    "        self.checkbox_frame = tk.Frame(master)\n",
    "        self.checkbox_frame.grid(row=6, column=1, padx=10)\n",
    "       \n",
    "        self.checkbox_labels = ['I_o', 'HSV', 'I_d', 'I_p', 'I_out', 'I_img', 'I_u', 'S']\n",
    "        self.checkbox_vars = [tk.BooleanVar() for i in range(len(self.checkbox_labels))]\n",
    "        self.checkbox_buttons = []\n",
    "        \n",
    "        for i in range(len(self.checkbox_labels)):\n",
    "            self.checkbox_buttons.append(tk.Checkbutton(self.checkbox_frame, text=self.checkbox_labels[i], variable=self.checkbox_vars[i],state='disabled'))\n",
    "            if i < len(self.checkbox_labels) // 2:\n",
    "                self.checkbox_buttons[i].grid(row=i, column=0, sticky='w')\n",
    "            else:\n",
    "                self.checkbox_buttons[i].grid(row=i-len(self.checkbox_labels) // 2, column=1, sticky='w')\n",
    "        \n",
    "        self.metric_table = ttk.Frame(master)\n",
    "        self.metric_table.grid(row=6, column=0, padx=5)\n",
    "        self.metric_table_label = ttk.Label(self.metric_table, text=\"Metric Table\")\n",
    "        self.metric_table_label.grid(row=7, column=0, pady=(0, 1))\n",
    "\n",
    "        self.metric_table_treeview = ttk.Treeview(self.metric_table, height=5)\n",
    "        self.metric_table_treeview.grid(row=8, column=0)\n",
    "        self.metric_table_treeview['columns'] = (\"Metric-Name\", \"Metric-Value\")\n",
    "\n",
    "        # format columns\n",
    "        self.metric_table_treeview.column(\"#0\", width=0, stretch=False)\n",
    "        self.metric_table_treeview.column(\"Metric-Name\", width=100, minwidth=100, anchor=\"center\")\n",
    "        self.metric_table_treeview.column(\"Metric-Value\", width=100, minwidth=100, anchor=\"center\")\n",
    "\n",
    "        # create headings\n",
    "        self.metric_table_treeview.heading(\"#0\", text=\"\", anchor=\"w\")\n",
    "        self.metric_table_treeview.heading(\"Metric-Name\", text=\"Metric-Name\", anchor=\"center\")\n",
    "        self.metric_table_treeview.heading(\"Metric-Value\", text=\"Metric-Value\", anchor=\"center\")\n",
    "        \n",
    "\n",
    "        # Run button\n",
    "        self.run_button = tk.Button(self.checkbox_frame, text=\"Run\",state='disabled', command=self.run)\n",
    "        self.run_button.grid(row=7, column=0, padx=10, pady=10 )\n",
    "\n",
    "          \n",
    "    \n",
    "    def en(self, event):\n",
    "        self.run_button.config(state='normal')\n",
    "        if self.model_combobox.get() == 'MSRCR':\n",
    "           self.values_entry_sigma.configure(state='normal')\n",
    "           self.values_entry_sigma.delete(0,'end')\n",
    "           self.values_entry_sigma.insert(1,'30,100,300')\n",
    "           self.values_entry_weight.configure(state='disable')\n",
    "           self.values_entry_kernel.configure(state='disable')\n",
    "           self.values_entry_lambda.configure(state='disable')\n",
    "           for i in range(len(self.checkbox_buttons)):\n",
    "               self.checkbox_buttons[i].configure(state='disable')\n",
    "               self.checkbox_buttons[i].deselect()\n",
    "           self.checkbox_buttons[0].configure(state='normal')\n",
    "\n",
    "        elif  self.model_combobox.get() == 'DFE': \n",
    "           self.values_entry_sigma.configure(state='normal')\n",
    "           self.values_entry_sigma.delete(0,'end')\n",
    "           self.values_entry_sigma.insert(1,'30,100,300')\n",
    "           self.values_entry_weight.configure(state='normal')\n",
    "           self.values_entry_weight.delete(0,'end')\n",
    "           self.values_entry_weight.insert(1,'0.01,0.01,0.25')\n",
    "           self.values_entry_kernel.configure(state='normal')\n",
    "           self.values_entry_kernel.delete(0,'end')\n",
    "           self.values_entry_kernel.insert(1,'9,9')\n",
    "           self.values_entry_lambda.configure(state='normal')\n",
    "           self.values_entry_lambda.delete(0,'end')\n",
    "           self.values_entry_lambda.insert(1,'40')\n",
    "           for i in range(len(self.checkbox_buttons)):\n",
    "               self.checkbox_buttons[i].configure(state='normal') \n",
    "\n",
    "        else:\n",
    "           self.values_entry_sigma.configure(state='disable')\n",
    "           self.values_entry_weight.configure(state='disable')\n",
    "           self.values_entry_kernel.configure(state='disable')\n",
    "           self.values_entry_lambda.configure(state='disable')\n",
    "           for i in range(len(self.checkbox_buttons)):\n",
    "               self.checkbox_buttons[i].configure(state='disable')\n",
    "               self.checkbox_buttons[i].deselect()\n",
    "           self.checkbox_buttons[0].configure(state='normal')\n",
    "\n",
    "        for i in self.metric_table_treeview.get_children():\n",
    "              self.metric_table_treeview.delete(i)         \n",
    "        \n",
    "    def select_image(self):\n",
    "        file_paths = filedialog.askopenfilenames(title=\"Select Image Files\", filetypes=[(\"Image files\", \"*.jpg;*.jpeg;*.png;*.gif;*.tif;*.bmp;\")])\n",
    "        if file_paths:\n",
    "            image = cv2.imread(file_paths[0])\n",
    "            self.image = cv2.resize(image, (640, 480))\n",
    "            self.select_image_button.config(state='normal')\n",
    "            self.model_combobox.config(state='readonly')\n",
    "        else:\n",
    "            self.image = None    \n",
    "\n",
    "    def display_selected(self):\n",
    "        disp_img(self.image , title = 'Reference' ,text = {'text' : ['Original'],'loc':[(280,460)]})\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()  \n",
    "\n",
    "    def insert_data_to_metric_table(self):\n",
    "        for i in self.metric_table_treeview.get_children():\n",
    "            self.metric_table_treeview.delete(i)\n",
    "\n",
    "        for idx, (key, value) in enumerate(self.info.items()):\n",
    "            self.metric_table_treeview.insert(parent='', index='end', iid=str(idx), values=(key, value))      \n",
    "    \n",
    "    def run(self):\n",
    "        # Get values from GUI elements\n",
    "        sigma =  None\n",
    "        weights = None\n",
    "        kernel = None  \n",
    "        lam = None\n",
    "        Img = self.image\n",
    "        model = self.model_combobox.get()\n",
    " \n",
    "        if model == 'DFE':\n",
    "           sigma = [int(num)for num in self.values_entry_sigma.get().split(',')]\n",
    "           weights = [float(num)for num in self.values_entry_weight.get().split(',')]\n",
    "           kernel = [int(num)for num in self.values_entry_kernel.get().split(',')]\n",
    "           lam = int(self.values_entry_lambda.get())\n",
    "        elif model == 'MSRCR': \n",
    "           sigma = [int(num)for num in self.values_entry_sigma.get().split(',')] \n",
    "        \n",
    "        \n",
    "        checkboxes = [var.get() for var in self.checkbox_vars]\n",
    "\n",
    "        # Display processed image\n",
    "        self.info = Model(Img ,model =model ,disp_selector = checkboxes,sigma = sigma,weights=weights ,kernel =kernel ,lam = lam)\n",
    "        self.insert_data_to_metric_table()\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    root = tk.Tk()\n",
    "    \n",
    "    gui = ImageProcessorGUI(root)\n",
    "    root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
